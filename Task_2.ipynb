{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxA39xwJ7qvMh0SpHftqTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyankajuttu/FUTURE_ML_02/blob/main/Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Update the file path below to the correct uploaded file location\n",
        "file_path = '/content/Spotify_data.xlsx'  # Replace with your actual file name\n",
        "\n",
        "# Load the Excel file\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display first few rows and info\n",
        "print(data.head())\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "id": "ADCvcDn-crkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in selected categorical columns with 'Unknown'\n",
        "cols_with_missing = ['preffered_premium_plan', 'fav_pod_genre', 'preffered_pod_format', 'pod_host_preference', 'preffered_pod_duration']\n",
        "data[cols_with_missing] = data[cols_with_missing].fillna('Unknown')\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(data_encoded.head())\n"
      ],
      "metadata": {
        "id": "qeBlxh0pdaDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define churn based on usage period and premium subscription willingness\n",
        "data['churn'] = ((data['spotify_usage_period'] == 'Less than 6 months') |\n",
        "                 (data['premium_sub_willingness'] == 'No')).astype(int)\n",
        "\n",
        "# Check the churn value counts\n",
        "print(data['churn'].value_counts())\n"
      ],
      "metadata": {
        "id": "K9GgO1UPdr9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Features and target\n",
        "X = data_encoded.drop(columns=['churn'])\n",
        "y = data_encoded['churn']\n",
        "\n",
        "# Split train-test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    print(f\"Evaluation for {model_name}\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
        "    print(\"ROC AUC:\", roc_auc_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Evaluate all models\n",
        "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
        "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
        "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n"
      ],
      "metadata": {
        "id": "DsVVJ6aydyP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create churn column\n",
        "data['churn'] = ((data['spotify_usage_period'] == 'Less than 6 months') |\n",
        "                 (data['premium_sub_willingness'] == 'No')).astype(int)\n",
        "\n",
        "# 2. Fill missing values as before (if not done)\n",
        "# ... (your missing value handling code here)\n",
        "\n",
        "# 3. One-hot encode ALL columns, including churn\n",
        "data_encoded = pd.get_dummies(data, columns=data.select_dtypes(include=['object']).columns, drop_first=True)\n",
        "\n",
        "# 4. Now split features and target\n",
        "X = data_encoded.drop(columns=['churn'])\n",
        "y = data_encoded['churn']\n"
      ],
      "metadata": {
        "id": "82vqdrozeJlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Add or update churn column first!\n",
        "data['churn'] = ((data['spotify_usage_period'] == 'Less than 6 months') |\n",
        "                 (data['premium_sub_willingness'] == 'No')).astype(int)\n",
        "\n",
        "# Step 2: Handle missing values as before\n",
        "cols_with_missing = ['preffered_premium_plan', 'fav_pod_genre', 'preffered_pod_format', 'pod_host_preference', 'preffered_pod_duration']\n",
        "data[cols_with_missing] = data[cols_with_missing].fillna('Unknown')\n",
        "\n",
        "# Step 3: One-hot encode (including churn)\n",
        "data_encoded = pd.get_dummies(data, columns=data.select_dtypes(include=['object']).columns, drop_first=True)\n",
        "\n",
        "# Step 4: Split into features and target\n",
        "X = data_encoded.drop(columns=['churn'])\n",
        "y = data_encoded['churn']\n"
      ],
      "metadata": {
        "id": "lczKzS3yeTJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Features and target\n",
        "X = data_encoded.drop(columns=['churn'])\n",
        "y = data_encoded['churn']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    print(f\"Evaluation for {model_name}\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
        "    print(\"ROC AUC:\", roc_auc_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Evaluate all models\n",
        "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
        "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
        "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n"
      ],
      "metadata": {
        "id": "vtCi6fF4etQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get feature importance from XGBoost (best model)\n",
        "importances = xgb.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "feature_names = X.columns\n",
        "\n",
        "# Plot top 10 important features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Top 10 Feature Importances (XGBoost)\")\n",
        "plt.bar(range(10), importances[indices][:10], align=\"center\")\n",
        "plt.xticks(range(10), [feature_names[i] for i in indices[:10]], rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Djyu_BTXe9i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export feature importances\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "fi_df = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': xgb.feature_importances_\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "fi_df.to_csv('feature_importance.csv', index=False)\n",
        "\n",
        "# Export model metrics\n",
        "metrics = {\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'],\n",
        "    'Logistic_Regression': [0.99, 1.0, 0.98, 0.99, 0.99],\n",
        "    'Random_Forest': [0.97, 0.97, 0.98, 0.98, 0.97],\n",
        "    'XGBoost': [1.0, 1.0, 1.0, 1.0, 1.0]\n",
        "}\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df.to_csv('model_metrics.csv', index=False)\n",
        "\n",
        "# Export confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "cm_df = pd.DataFrame(cm, columns=['Predicted_No','Predicted_Yes'], index=['Actual_No','Actual_Yes'])\n",
        "cm_df.to_csv('confusion_matrix.csv')\n",
        "\n",
        "# Export churn probabilities with true/false labels\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual': y_test,\n",
        "    'Predicted': y_pred_xgb,\n",
        "    'Churn_Probability': xgb.predict_proba(X_test)[:,1]\n",
        "})\n",
        "results_df.to_csv('churn_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "U-izWVytiCg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export your complete cleaned dataframe (with churn column)\n",
        "data.to_csv('cleaned_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "sqMYKCnLi7OT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}